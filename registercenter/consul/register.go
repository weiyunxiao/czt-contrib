package consul

import (
	"fmt"
	"net"
	"os"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/hashicorp/consul/api"
	"github.com/zeromicro/go-zero/core/logx"
	"github.com/zeromicro/go-zero/core/netx"
	"github.com/zeromicro/go-zero/core/proc"
)

type (
	// Client is the interface for Consul service client.
	Client interface {
		RegisterService() error
		DeregisterService() error
		GetServiceID() string
		GetRegistration() *api.AgentServiceRegistration
		GetServiceClient() *api.Client
	}

	// CommonClient is the common implementation of Client.
	CommonClient struct {
		registration   *api.AgentServiceRegistration
		apiClient      *api.Client
		serviceId      string
		serviceHost    string
		servicePort    int
		consulConf     Conf
		monitorFuncs   []MonitorFunc
		monitorMutex   sync.RWMutex
		stopMonitorChs []chan struct{}
		stopChMutex    sync.Mutex
	}

	// MonitorState holds the state for the health check monitor.
	MonitorState struct {
		RetryCount     int
		BackoffTime    time.Duration
		MaxBackoffTime time.Duration
		MaxRetries     int
		Ticker         *time.Ticker
		OriginalTTL    time.Duration // 保存原始的TTL值，用于重置
		Mutex          sync.RWMutex
	}

	// MonitorFunc is the function signature for health check monitor functions.
	MonitorFunc func(cc *CommonClient, stopChan <-chan struct{})

	// ServiceOption is the function signature for service options.
	ServiceOption func(*CommonClient)
)

// MustNewService creates a new Consul service client.
// It panics if the configuration is invalid.
func MustNewService(listenOn string, c Conf, opts ...ServiceOption) Client {
	service, err := NewService(listenOn, c, opts...)
	if err != nil {
		logx.Must(err)
	}
	return service
}

// NewService creates a new Consul service client.
// It returns a Client instance or an error if the configuration is invalid.
// The listenOn parameter specifies the local address to bind the service to.
// The c parameter specifies the Consul configuration.
// The opts parameter allows for additional monitor functions to be added. use WithMonitorFunc to add monitor functions.
func NewService(listenOn string, c Conf, opts ...ServiceOption) (Client, error) {
	if err := c.Validate(); err != nil {
		return nil, err
	}

	pubListenOn := figureOutListenOn(listenOn)

	host, ports, err := net.SplitHostPort(pubListenOn)
	if err != nil {
		return nil, fmt.Errorf("failed parsing address error: %v", err)
	}
	port, _ := strconv.ParseUint(ports, 10, 16)

	service := &CommonClient{
		registration: nil,
		serviceId:    fmt.Sprintf("%s-%s-%d", c.Key, host, port),
		serviceHost:  host,
		servicePort:  int(port),
		consulConf:   c,
		monitorFuncs: make([]MonitorFunc, 0),
	}

	for _, option := range opts {
		option(service)
	}

	client, err := service.newApiClient()
	if err != nil {
		return nil, fmt.Errorf("create consul client error: %v", err)
	}
	service.apiClient = client

	err = service.clientRegistration()
	if err != nil {
		return nil, err
	}

	return service, nil
}

// RegisterService registers the service with Consul.
// It returns an error if the registration fails.
// The service is registered with a passing health check.
func (cc *CommonClient) RegisterService() error {
	err := cc.registerServiceWithPassingHealth()
	if err != nil {
		return err
	}

	err = cc.registerServiceMonitors()
	if err != nil {
		return err
	}

	proc.AddShutdownListener(func() {
		cc.stopAllMonitors()
		err := cc.deleteRegisterService()
		if err != nil {
			logx.Errorf("deregister service %s error: %s", cc.serviceId, err.Error())
		} else {
			logx.Infof("Service %s deregistered successfully", cc.serviceId)
		}
	})
	return nil
}

// DeregisterService deregisters the service from Consul.
// It returns an error if the deregistration fails.
func (cc *CommonClient) DeregisterService() error {
	cc.stopAllMonitors()
	return cc.deleteRegisterService()
}

// GetServiceID returns the service ID.
func (cc *CommonClient) GetServiceID() string {
	return cc.serviceId
}

// GetServiceClient returns the Consul service client.
func (cc *CommonClient) GetServiceClient() *api.Client {
	return cc.apiClient
}

// GetRegistration returns the service registration.
func (cc *CommonClient) GetRegistration() *api.AgentServiceRegistration {
	return cc.registration
}

// newApiClient creates a new Consul service client.
func (cc *CommonClient) newApiClient() (*api.Client, error) {
	return api.NewClient(&api.Config{
		Scheme:  cc.consulConf.Scheme,
		Address: cc.consulConf.Host,
		Token:   cc.consulConf.Token,
	})
}

// registerServiceWithPassingHealth registers the service with a passing health check.
// It returns an error if the registration fails.
func (cc *CommonClient) registerServiceWithPassingHealth() error {
	/****************获取所有节点,遍历注销服务*********************/
	selfNodeName, _ := cc.apiClient.Agent().NodeName()

	nodeMembers, err := cc.apiClient.Agent().Members(false)
	for _, member := range nodeMembers {
		//如果是当前节点
		if member.Name == selfNodeName {
			continue
		}
		nodeAddr := fmt.Sprintf("%s:%d", member.Addr, member.Port)
		logx.Infof("one node info is:%s", nodeAddr)

		client, err := api.NewClient(&api.Config{
			Scheme:  "http",
			Address: nodeAddr,
			Token:   cc.consulConf.Token,
		})
		if err != nil {
			logx.Errorf("nodeAddr=%s,api.NewClient() have error: %s", nodeAddr, err.Error())
			continue
		}
		err = client.Agent().ServiceDeregister(cc.serviceId)
		if err != nil {
			logx.Errorf("nodeAddr=%s,ServiceDeregister() have error: %s", nodeAddr, err.Error())
			continue
		}
	}
	/****************获取所有节点,遍历注销服务 end ****************/

	_ = cc.deleteRegisterService()
	time.Sleep(100 * time.Millisecond)

	err = cc.registerService()
	if err != nil {
		return err
	}

	err = cc.setRegisterServiceHealthStatus(api.HealthPassing)
	if err != nil {
		_ = cc.deleteRegisterService()
		return fmt.Errorf("register service %s id %s check error: %v",
			cc.registration.Name, cc.registration.ID, err)
	}

	logx.Infof("Service %s id %s registered successfully", cc.registration.Name, cc.registration.ID)

	return nil
}

// registerService registers the service with Consul.
// It returns an error if the registration fails.
func (cc *CommonClient) registerService() error {
	err := cc.apiClient.Agent().ServiceRegister(cc.registration)
	if err != nil {
		return fmt.Errorf("register service %s id %s host to consul error: %s",
			cc.registration.Name, cc.registration.ID, err.Error())
	}
	return nil
}

// clientRegistration creates the service registration.
// switch check type to create different health check, such as TTL, gRPC, HTTP.
func (cc *CommonClient) clientRegistration() error {
	reg := &api.AgentServiceRegistration{
		ID:      cc.serviceId,       // Service node name
		Name:    cc.consulConf.Key,  // Service name
		Tags:    cc.consulConf.Tag,  // Tags, can be empty
		Meta:    cc.consulConf.Meta, // Meta, can be empty
		Port:    cc.servicePort,     // Service port
		Address: cc.serviceHost,     // Service IP
	}

	switch cc.consulConf.CheckType {
	case CheckTypeTTL:
		reg.Checks = []*api.AgentServiceCheck{
			{
				CheckID:                        cc.serviceId,                          // Service node name
				TTL:                            fmt.Sprintf("%ds", cc.consulConf.TTL), // Health check interval
				Status:                         api.HealthPassing,
				DeregisterCriticalServiceAfter: fmt.Sprintf("%ds", cc.consulConf.TTL*cc.consulConf.ExpiredTTL), // Deregistration time
			},
		}

	case CheckTypeGrpc:
		reg.Checks = []*api.AgentServiceCheck{
			{
				CheckID:                        cc.serviceId,                                         // Service node name
				GRPC:                           fmt.Sprintf("%s:%d", cc.serviceHost, cc.servicePort), // health check method
				TLSServerName:                  cc.consulConf.CheckGrpc.TLSServerName,
				TLSSkipVerify:                  cc.consulConf.CheckGrpc.TLSSkipVerify,
				GRPCUseTLS:                     cc.consulConf.CheckGrpc.GRPCUseTLS,
				Interval:                       fmt.Sprintf("%ds", cc.consulConf.TTL),          // health check interval
				Timeout:                        fmt.Sprintf("%ds", cc.consulConf.CheckTimeout), // health check timeout
				DeregisterCriticalServiceAfter: fmt.Sprintf("%ds", cc.consulConf.TTL*cc.consulConf.ExpiredTTL),
				Status:                         api.HealthPassing,
			},
		}
	case CheckTypeHttp:
		// todo 可以考虑混合健康检查，例如TTL和HTTP
		httpCheckHost := figureOutListenOn(fmt.Sprintf("%s:%d", cc.consulConf.CheckHttp.Host, cc.consulConf.CheckHttp.Port))
		reg.Checks = []*api.AgentServiceCheck{
			{
				CheckID:                        cc.serviceId,                                                                                          // Service node name
				HTTP:                           fmt.Sprintf("%s://%s%s", cc.consulConf.CheckHttp.Scheme, httpCheckHost, cc.consulConf.CheckHttp.Path), // health check url
				Method:                         cc.consulConf.CheckHttp.Method,                                                                        // health check method
				Interval:                       fmt.Sprintf("%ds", cc.consulConf.TTL),                                                                 // health check interval
				Timeout:                        fmt.Sprintf("%ds", cc.consulConf.CheckTimeout),                                                        // health check timeout
				DeregisterCriticalServiceAfter: fmt.Sprintf("%ds", cc.consulConf.TTL*cc.consulConf.ExpiredTTL),
				Status:                         api.HealthPassing,
			},
		}
	default:
		return fmt.Errorf("unknown check type: %s", cc.consulConf.CheckType)
	}
	cc.registration = reg
	return nil
}

// deleteRegisterService deregisters the service from Consul.
// It returns an error if the deregistration fails.
func (cc *CommonClient) deleteRegisterService() error {
	err := cc.apiClient.Agent().ServiceDeregister(cc.serviceId)
	return err
}

// setRegisterServiceHealthStatus sets the health status of the service.
// status is the health status to set, such as api.HealthPassing or api.HealthCritical.
// switch check type to set different health check status. such as TTL, gRPC, HTTP.
func (cc *CommonClient) setRegisterServiceHealthStatus(status string) error {
	switch cc.consulConf.CheckType {
	case CheckTypeTTL:
		check := api.AgentServiceCheck{
			TTL:                            fmt.Sprintf("%ds", cc.consulConf.TTL),
			Status:                         status,
			DeregisterCriticalServiceAfter: fmt.Sprintf("%ds", cc.consulConf.TTL*cc.consulConf.ExpiredTTL),
		}
		return cc.apiClient.Agent().CheckRegister(&api.AgentCheckRegistration{
			ID:                cc.registration.ID,
			Name:              cc.registration.Name,
			ServiceID:         cc.registration.ID,
			AgentServiceCheck: check,
		})
	case CheckTypeHttp:
		httpCheckHost := figureOutListenOn(fmt.Sprintf("%s:%d", cc.consulConf.CheckHttp.Host, cc.consulConf.CheckHttp.Port))
		check := api.AgentServiceCheck{
			HTTP:                           fmt.Sprintf("%s://%s%s", cc.consulConf.CheckHttp.Scheme, httpCheckHost, cc.consulConf.CheckHttp.Path), // health check url
			Method:                         cc.consulConf.CheckHttp.Method,                                                                        // health check method
			Interval:                       fmt.Sprintf("%ds", cc.consulConf.TTL),                                                                 // health check interval
			Timeout:                        fmt.Sprintf("%ds", cc.consulConf.CheckTimeout),                                                        // health check timeout
			DeregisterCriticalServiceAfter: fmt.Sprintf("%ds", cc.consulConf.TTL*cc.consulConf.ExpiredTTL),                                        // Deregistration time
			Status:                         status,
		}
		return cc.apiClient.Agent().CheckRegister(&api.AgentCheckRegistration{
			ID:                cc.registration.ID,
			Name:              cc.registration.Name,
			ServiceID:         cc.registration.ID,
			AgentServiceCheck: check,
		})
	case CheckTypeGrpc:
		check := api.AgentServiceCheck{
			GRPC:                           fmt.Sprintf("%s:%d", cc.serviceHost, cc.servicePort), // health check method
			TLSServerName:                  cc.consulConf.CheckGrpc.TLSServerName,
			TLSSkipVerify:                  cc.consulConf.CheckGrpc.TLSSkipVerify,
			GRPCUseTLS:                     cc.consulConf.CheckGrpc.GRPCUseTLS,                             // health check method
			Interval:                       fmt.Sprintf("%ds", cc.consulConf.TTL),                          // health check interval
			Timeout:                        fmt.Sprintf("%ds", cc.consulConf.CheckTimeout),                 // health check timeout
			DeregisterCriticalServiceAfter: fmt.Sprintf("%ds", cc.consulConf.TTL*cc.consulConf.ExpiredTTL), // Deregistration time
			Status:                         status,
		}
		return cc.apiClient.Agent().CheckRegister(&api.AgentCheckRegistration{
			ID:                cc.registration.ID,
			Name:              cc.registration.Name,
			ServiceID:         cc.registration.ID,
			AgentServiceCheck: check,
		})
	default:
		return fmt.Errorf("unknown check type: %s", cc.consulConf.CheckType)
	}
}

// getRegisterServiceHealthStatus returns the health status of the service.
func (cc *CommonClient) getRegisterServiceHealthStatus() (string, error) {
	service, _, err := cc.apiClient.Agent().Service(cc.serviceId, nil)
	if err != nil {
		return "", fmt.Errorf("failed to get service %s: %v", cc.serviceId, err)
	}

	serviceEntries, _, err := cc.apiClient.Health().Service(service.Service, "", false, nil)
	if err != nil {
		return "", fmt.Errorf("failed to get service %s health: %v", cc.serviceId, err)
	}

	for _, entry := range serviceEntries {
		if entry.Service.ID == cc.serviceId {
			return entry.Checks.AggregatedStatus(), nil
		}
	}
	return "", fmt.Errorf("service %s not found in health check results", cc.serviceId)
}

// registerServiceHealthStatus checks if the service health status is as expected.
// status is the expected health status, such as api.HealthPassing or api.HealthCritical.
// It returns true if the status matches, otherwise false.
func (cc *CommonClient) registerServiceHealthStatus(status string) (bool, error) {
	ss, err := cc.getRegisterServiceHealthStatus()
	if err != nil {
		return false, err
	}

	if ss != status {
		return false, fmt.Errorf("service status is %s, not %s", ss, status)
	}

	return true, nil
}

// registerServiceMonitors registers the service monitors based on the check type.
// switch check type to register different monitors. such as TTL, gRPC, HTTP.
// default monitor is TTLCheckMonitorFunc where type is TTL
// default monitor is HttpCheckMonitorFunc where type is HTTP
// default monitor is GrpcCheckMonitorFunc where type is gRPC
// you can use MustNewService opts param to add custom monitors.
func (cc *CommonClient) registerServiceMonitors() error {
	cc.monitorMutex.RLock()
	hasNoFuncs := len(cc.monitorFuncs) == 0
	cc.monitorMutex.RUnlock()

	if hasNoFuncs {
		cc.monitorMutex.Lock()
		if len(cc.monitorFuncs) == 0 {
			cc.monitorFuncs = append(cc.monitorFuncs, ApiClientCheckMonitorFunc())
			switch cc.consulConf.CheckType {
			case CheckTypeTTL:
				cc.monitorFuncs = append(cc.monitorFuncs, TTLCheckMonitorFunc())
			case CheckTypeGrpc:
				cc.monitorFuncs = append(cc.monitorFuncs, HttpCheckMonitorFunc())
			case CheckTypeHttp:
				cc.monitorFuncs = append(cc.monitorFuncs, HttpCheckMonitorFunc())
			default:
				return fmt.Errorf("unknown check type: %s", cc.consulConf.CheckType)
			}

		}
		cc.monitorMutex.Unlock()
	}

	cc.monitorMutex.RLock()
	funcsCopy := make([]MonitorFunc, len(cc.monitorFuncs))
	copy(funcsCopy, cc.monitorFuncs)
	cc.monitorMutex.RUnlock()
	cc.startMonitors(funcsCopy)
	return nil
}

// startMonitors starts the service monitors.
func (cc *CommonClient) startMonitors(funcs []MonitorFunc) {
	cc.stopChMutex.Lock()
	defer cc.stopChMutex.Unlock()

	for _, monitorFunc := range funcs {
		stopCh := make(chan struct{})
		cc.stopMonitorChs = append(cc.stopMonitorChs, stopCh)
		go monitorFunc(cc, stopCh)
	}
}

// stopAllMonitors stops all service monitors.
func (cc *CommonClient) stopAllMonitors() {
	cc.stopChMutex.Lock()
	defer cc.stopChMutex.Unlock()

	for _, stopCh := range cc.stopMonitorChs {
		close(stopCh)
	}
	cc.stopMonitorChs = make([]chan struct{}, 0)
}

func (s *MonitorState) Close() {
	s.Mutex.Lock()
	defer s.Mutex.Unlock()
	if s.Ticker != nil {
		s.Ticker.Stop()
		s.Ticker = nil
	}
}

// ApiClientCheckMonitorFunc is the monitor function for ApiClient check.
func ApiClientCheckMonitorFunc() MonitorFunc {

	return func(cc *CommonClient, stopCh <-chan struct{}) {

		ttlTicker := 20 * time.Second

		state := &MonitorState{
			RetryCount:     0,
			BackoffTime:    2 * time.Second,
			MaxRetries:     3,
			MaxBackoffTime: 30 * time.Second,
			OriginalTTL:    ttlTicker,
			Ticker:         time.NewTicker(ttlTicker),
		}
		defer state.Close()

		for {
			select {
			case <-state.Ticker.C:
				err := ApiClientLogic(cc, state)
				if err != nil {
					logx.Errorf("ApiClientCheckMonitorFunc function error for service %s: %v", cc.serviceId, err)
				}
			case <-stopCh:
				logx.Infof("ApiClientCheckMonitorFunc Service monitor for %s stopped gracefully", cc.serviceId)
				return
			}
		}
	}
}

// ApiClientLogic is the logic for ApiClient monitor.
func ApiClientLogic(cc *CommonClient, state *MonitorState) error {
	// update TTL
	_, err := cc.apiClient.Status().Leader()
	if err == nil {
		logx.Infof("Service %s, ApiClient now is ok", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 2 * time.Second
		state.Ticker.Reset(state.OriginalTTL)
		return nil
	}

	state.Mutex.Lock()
	defer state.Mutex.Unlock()
	if state.RetryCount < state.MaxRetries {
		logx.Infof("Attempting to recreate-ApiClient service %s (retry %d/%d)...", cc.serviceId, state.RetryCount+1, state.MaxRetries)
		client, err := cc.newApiClient()
		if err != nil {
			logx.Errorf("Failed to recreate-ApiClient service %s: %v. Retrying in %v", cc.serviceId, err, state.BackoffTime)
			state.RetryCount++

			state.Ticker.Reset(state.BackoffTime)
			nextBackoffTime := state.BackoffTime * 2
			if nextBackoffTime > state.MaxBackoffTime {
				nextBackoffTime = state.MaxBackoffTime
			}
			state.BackoffTime = nextBackoffTime
			return err
		}
		cc.apiClient = client
		logx.Infof("Service %s recreate-ApiClientd successfully", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 2 * time.Second
		state.Ticker.Reset(state.OriginalTTL)
		return nil
	}

	// reset retry counter and backoff time if not registered
	logx.Errorf("recreate-ApiClientd Max retries reached for service %s. Resetting retry counter and backoff time.", cc.serviceId)
	state.RetryCount = 0
	state.BackoffTime = 1 * time.Second
	state.Ticker.Reset(state.BackoffTime)
	return nil
}

// TTLCheckMonitorFunc is the monitor function for TTL check.
func TTLCheckMonitorFunc() MonitorFunc {
	return func(cc *CommonClient, stopCh <-chan struct{}) {
		var ttlTicker time.Duration
		if cc.consulConf.TTL > 0 {
			ttlTicker = time.Duration(cc.consulConf.TTL-1) * time.Second
			if ttlTicker < time.Second {
				ttlTicker = time.Second
			}
		} else {
			ttlTicker = 1 * time.Second
		}

		state := &MonitorState{
			RetryCount:     0,
			BackoffTime:    1 * time.Second,
			MaxRetries:     5,
			MaxBackoffTime: 30 * time.Second,
			OriginalTTL:    ttlTicker,
			Ticker:         time.NewTicker(ttlTicker),
		}
		defer state.Close()

		for {
			select {
			case <-state.Ticker.C:
				err := TTLMonitorLogic(cc, state)
				if err != nil {
					logx.Errorf("Monitor function error for service %s: %v", cc.serviceId, err)
				}
			case <-stopCh:
				logx.Infof("Service monitor for %s stopped gracefully", cc.serviceId)
				return
			}
		}

	}
}

// TTLMonitorLogic is the logic for TTL monitor.
func TTLMonitorLogic(cc *CommonClient, state *MonitorState) error {

	// update TTL
	err := cc.apiClient.Agent().UpdateTTL(cc.serviceId, "", "passing")
	if err == nil {
		logx.Infof("Service %s TTL updated successfully", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 1 * time.Second
		state.Ticker.Reset(state.OriginalTTL)
		return nil
	}

	registered, err := cc.registerServiceHealthStatus(api.HealthPassing)
	if err != nil {
		logx.Error(err)
	} else {
		registered = true
	}

	state.Mutex.Lock()
	defer state.Mutex.Unlock()
	if !registered && state.RetryCount < state.MaxRetries {
		logx.Infof("Attempting to re-register service %s (retry %d/%d)...", cc.serviceId, state.RetryCount+1, state.MaxRetries)
		err = cc.registerServiceWithPassingHealth()
		if err != nil {
			logx.Errorf("Failed to re-register service %s: %v. Retrying in %v", cc.serviceId, err, state.BackoffTime)
			state.RetryCount++

			state.Ticker.Reset(state.BackoffTime)
			nextBackoffTime := state.BackoffTime * 2
			if nextBackoffTime > state.MaxBackoffTime {
				nextBackoffTime = state.MaxBackoffTime
			}
			state.BackoffTime = nextBackoffTime
			return err
		}

		logx.Infof("Service %s re-registered successfully", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 1 * time.Second
		state.Ticker.Reset(state.OriginalTTL)
		return nil
	}

	// reset retry counter and backoff time if not registered
	if !registered {
		logx.Errorf("Max retries reached for service %s. Resetting retry counter and backoff time.", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 1 * time.Second
		state.Ticker.Reset(state.BackoffTime)
	}
	return nil
}

// HttpCheckMonitorFunc is the monitor function for HTTP check.
func HttpCheckMonitorFunc() MonitorFunc {

	return func(cc *CommonClient, stopCh <-chan struct{}) {
		var ttlTicker time.Duration
		if cc.consulConf.TTL > 0 {
			ttlTicker = time.Duration(cc.consulConf.TTL-1) * time.Second
			if ttlTicker < time.Second {
				ttlTicker = time.Second
			}
		} else {
			ttlTicker = 1 * time.Second
		}

		state := &MonitorState{
			RetryCount:     0,
			BackoffTime:    1 * time.Second,
			MaxRetries:     5,
			MaxBackoffTime: 30 * time.Second,
			OriginalTTL:    ttlTicker,
			Ticker:         time.NewTicker(ttlTicker),
		}
		defer state.Close()

		for {
			select {
			case <-state.Ticker.C:
				err := HttpMonitorLogic(cc, state)
				if err != nil {
					logx.Errorf("Monitor function error for service %s: %v", cc.serviceId, err)
				}
			case <-stopCh:
				logx.Infof("Service monitor for %s stopped gracefully", cc.serviceId)
				return
			}
		}
	}
}

// HttpMonitorLogic is the logic for HTTP monitor.
func HttpMonitorLogic(cc *CommonClient, state *MonitorState) error {
	registered, err := cc.registerServiceHealthStatus(api.HealthPassing)
	if err != nil {
		logx.Error(err)
	} else {
		logx.Infof("Service %s health check passed", cc.serviceId)
		registered = true
	}

	state.Mutex.Lock()
	defer state.Mutex.Unlock()
	if !registered && state.RetryCount < state.MaxRetries {
		logx.Infof("Attempting to re-register service %s (retry %d/%d)...", cc.serviceId, state.RetryCount+1, state.MaxRetries)
		err = cc.registerServiceWithPassingHealth()
		if err != nil {
			logx.Errorf("Failed to re-register service %s: %v. Retrying in %v", cc.serviceId, err, state.BackoffTime)
			state.RetryCount++

			state.Ticker.Reset(state.BackoffTime)
			nextBackoffTime := state.BackoffTime * 2
			if nextBackoffTime > state.MaxBackoffTime {
				nextBackoffTime = state.MaxBackoffTime
			}
			state.BackoffTime = nextBackoffTime
			return err
		}

		logx.Infof("Service %s re-registered successfully", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 1 * time.Second
		state.Ticker.Reset(state.OriginalTTL)
		return nil
	}

	// 达到最大重试次数
	if !registered {
		logx.Errorf("Max retries reached for service %s. Resetting retry counter and backoff time.", cc.serviceId)
		state.RetryCount = 0
		state.BackoffTime = 1 * time.Second
		state.Ticker.Reset(state.BackoffTime)
	}
	return nil
}

// figureOutListenOn figures out the listen on address.
// if your host is "0.0.0.0", it will be replaced with the environment variable POD_IP or the internal IP.
// example: "0.0.0.0:8080" -> "10.10.10.10:8080"
func figureOutListenOn(listenOn string) string {
	fields := strings.Split(listenOn, ":")
	if len(fields) == 0 {
		return listenOn
	}

	host := fields[0]
	if len(host) > 0 && host != allEths {
		return listenOn
	}

	ip := os.Getenv(envPodIP)
	if len(ip) == 0 {
		ip = netx.InternalIp()
	}
	if len(ip) == 0 {
		return listenOn
	}

	return strings.Join(append([]string{ip}, fields[1:]...), ":")
}

// WithMonitorFuncs sets the monitor functions for the service.
// example: MustNewService(listenOn, WithMonitorFuncs(TTLCheckMonitorFunc(), HttpCheckMonitorFunc()))
func WithMonitorFuncs(funcs ...MonitorFunc) ServiceOption {
	return func(cc *CommonClient) {
		cc.monitorMutex.Lock()
		defer cc.monitorMutex.Unlock()
		cc.monitorFuncs = append(cc.monitorFuncs, funcs...)
	}
}
